{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_analysis_frozen_bert_pytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "17154c35d2a64da689b1cfea0f7815a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a92b51ec831e4a60934e607f5fd73946",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dd8ac7ccba1940deac14ecb1e49bfebb",
              "IPY_MODEL_fa532b00fc664157bf88051282af0e1d"
            ]
          }
        },
        "a92b51ec831e4a60934e607f5fd73946": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dd8ac7ccba1940deac14ecb1e49bfebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_52693cc833074f1093e963317409cdf0",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bbd92d7484b24e26b5af20a42f5847c9"
          }
        },
        "fa532b00fc664157bf88051282af0e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c2a489b19ad849b395ba69c41570e010",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 232k/232k [00:00&lt;00:00, 916kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8680658f7ff4e0484a8ac61b84ce3f9"
          }
        },
        "52693cc833074f1093e963317409cdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bbd92d7484b24e26b5af20a42f5847c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2a489b19ad849b395ba69c41570e010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8680658f7ff4e0484a8ac61b84ce3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d525ad82599d456b8193d3497817a23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18b41f35960c4899b38e68091593851d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_08333ecd9456425181194d51964b6c3e",
              "IPY_MODEL_7f0d8a977a85466bb806bf5828e8544e"
            ]
          }
        },
        "18b41f35960c4899b38e68091593851d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08333ecd9456425181194d51964b6c3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0399974672f4feebfebd54d667a5cda",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ede328f416fa41d0b24f4899ea118bbf"
          }
        },
        "7f0d8a977a85466bb806bf5828e8544e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_61dc91d67888411188ef1a22171b4fe9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 361/361 [00:00&lt;00:00, 5.21kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5aaf5a479f7942fa9c3f680fb85f4a95"
          }
        },
        "b0399974672f4feebfebd54d667a5cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ede328f416fa41d0b24f4899ea118bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61dc91d67888411188ef1a22171b4fe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5aaf5a479f7942fa9c3f680fb85f4a95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "089bd16c0b7448e88bed586a8cf57b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5e693ab34aea4bf399b76028d4bdaa5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2e1226f82f884885a2ebf7af517629b4",
              "IPY_MODEL_6b05b76174ac4a5c81e521ff089f4bfd"
            ]
          }
        },
        "5e693ab34aea4bf399b76028d4bdaa5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2e1226f82f884885a2ebf7af517629b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_304a6132eb014c0eae72aaddabad4bf1",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f02a369bf84c74b1d97bab108663f0"
          }
        },
        "6b05b76174ac4a5c81e521ff089f4bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ca3b1935f5bd45aaaef0856303eb1188",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 440M/440M [00:16&lt;00:00, 26.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b0e6ff11a48482f908104c586aee337"
          }
        },
        "304a6132eb014c0eae72aaddabad4bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f02a369bf84c74b1d97bab108663f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ca3b1935f5bd45aaaef0856303eb1188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b0e6ff11a48482f908104c586aee337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPs1FLDrPOX9",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with Frozen Bert\n",
        "\n",
        "In another Bert text classification tutorial, we fine-tuned Bert model (i.e. updated all of its weights). In this tutorial, we will freeze (not train) the transformer and only train the remainder of the model which learns from the representations produced by the transformer. In this case we will be using a **multi-layer bi-directional GRU**, however any other model can learn from these representations.\n",
        "\n",
        "Note: any codes are same as previous tutorial are not given textual comments for simplicity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxE1Jv8hQGBl",
        "colab_type": "text"
      },
      "source": [
        "## Preparing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSmyBuY_PVmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "e2b9a239-f2e1-40a2-ed2c-c2e92be514e9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 25.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 42.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 42.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=5e1712b7d3f9bf0b48d87812557b76fb74760751ccb20a8f658e234d078d7567\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh1Zlzy1QNKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykveEszxUXKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129,
          "referenced_widgets": [
            "17154c35d2a64da689b1cfea0f7815a9",
            "a92b51ec831e4a60934e607f5fd73946",
            "dd8ac7ccba1940deac14ecb1e49bfebb",
            "fa532b00fc664157bf88051282af0e1d",
            "52693cc833074f1093e963317409cdf0",
            "bbd92d7484b24e26b5af20a42f5847c9",
            "c2a489b19ad849b395ba69c41570e010",
            "f8680658f7ff4e0484a8ac61b84ce3f9"
          ]
        },
        "outputId": "e1b213b4-b544-48e7-9e3a-ae04e6753342"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17154c35d2a64da689b1cfea0f7815a9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GztNJaQAU78O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11e010b4-f0ac-4e65-cf2d-a295630d8da0"
      },
      "source": [
        "len(tokenizer.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnEsTqZ_VF8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0160d1e2-8bf9-4124-bdda-8deba40e301a"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCI_q4IDVSd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8aa9fa6d-6b06-4e3c-da3b-b1ec72a1aba2"
      },
      "source": [
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnS_H6nsVaDf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4988a69-2bba-4264-90a3-9940978257a6"
      },
      "source": [
        "MAX_INPUT_LENGTH = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "print(MAX_INPUT_LENGTH)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3hiyYHeVssW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(sentence, max_length):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "    tokens = tokens[:max_length-2]\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bllIvOzpvGF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f73df9b1-1e0d-4a25-d533-07c79161994a"
      },
      "source": [
        "tokens = tokenizer.encode('Hello WORLD how ARE yoU?', max_length=MAX_INPUT_LENGTH)\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 7592, 2088, 2129, 2024, 2017, 1029, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h13ksr5GWj45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data, datasets\n",
        "TEXT = data.Field(\n",
        "    batch_first = True,\n",
        "    use_vocab = False, ### already built in Bert \n",
        "    tokenize = lambda x:tokenizer.encode(x, max_length=MAX_INPUT_LENGTH),\n",
        "    # tokenize = lambda x:tokenize_and_cut(x, max_length=MAX_INPUT_LENGTH),\n",
        "    # preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "    # init_token = init_token_idx,\n",
        "    # eos_token = eos_token_idx,\n",
        "    pad_token = pad_token_idx,\n",
        "    unk_token = unk_token_idx\n",
        ")\n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-JFncKNXrU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d3bd8444-2e8e-44f7-fda7-d9555fcc4a0f"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:07<00:00, 10.5MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dt9RSgUcpJzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0efc3d50-84c8-4457-f191-5694e720afc4"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KLadgZOrhYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "61f6ff1f-502e-453a-f0e8-e9e2eb88c370"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [101, 2023, 2003, 2069, 5399, 8702, 2005, 4599, 1997, 1000, 2919, 3185, 1000, 4024, 1012, 2009, 2003, 2062, 4276, 19927, 2005, 2493, 1997, 3359, 1005, 1055, 3769, 3226, 1024, 1996, 4827, 2015, 1010, 1996, 7390, 1010, 1996, 13818, 1010, 1998, 2008, 2307, 1000, 2308, 1005, 1055, 5622, 2497, 1000, 2617, 1997, 1996, 2220, 3359, 1005, 1055, 1010, 2043, 2009, 2001, 2145, 4840, 1998, 3117, 2005, 1037, 2969, 1011, 4846, 1010, 2981, 2450, 2000, 4839, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1000, 3565, 5428, 3600, 1000, 1006, 11830, 10454, 3385, 1007, 2018, 1037, 12256, 12928, 11272, 10377, 2075, 2065, 24646, 7096, 11787, 2476, 1006, 2044, 2035, 1010, 2054, 2003, 1037, 3462, 16742, 2021, 1037, 13877, 2012, 2382, 1010, 2199, 2519, 1011, 1011, 2008, 3632, 2005, 1996, 3287, 3924, 2205, 1007, 1010, 2016, 7771, 2105, 2007, 3674, 2273, 1010, 2071, 4047, 2841, 1998, 2500, 1006, 2007, 16894, 1007, 1998, 2347, 1005, 1056, 5079, 2091, 2000, 2505, 1012, 2023, 2003, 1996, 2785, 1997, 7861, 2319, 6895, 17585, 2094, 2450, 2008, 6015, 1996, 10869, 2015, 2041, 1997, 3424, 1011, 10469, 2015, 1010, 2216, 22307, 24170, 28781, 2040, 2903, 2008, 2053, 2450, 2003, 3143, 2302, 1037, 3129, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 1000, 7916, 17946, 7971, 1000, 2001, 1037, 16834, 7905, 27405, 5051, 1997, 1996, 2397, 3624, 1005, 1055, 2000, 3359, 1005, 1055, 1010, 1006, 20277, 2480, 1010, 2130, 2006, 1000, 1996, 26079, 2155, 1010, 1000, 1045, 3342, 11820, 5065, 19469, 24510, 7887, 8103, 2075, 2039, 2007, 17946, 26636, 1007, 1998, 2013, 2008, 2391, 1997, 3193, 1010, 2023, 10021, 2143, 2003, 2019, 2590, 3769, 3226, 2051, 18269, 1997, 1996, 3653, 1011, 8387, 1010, 2489, 1011, 2293, 1010, 2308, 1005, 1055, 5622, 2497, 1010, 11820, 26232, 1012, 1996, 5436, 2003, 3243, 9643, 2295, 1012, 1998, 2005, 2216, 5430, 3549, 1999, 1996, 4378, 1010, 2045, 2024, 2261, 6436, 12682, 2000, 2298, 2012, 1012, 102], 'label': 'neg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNmx2vYqrk_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "12172b22-ba1d-4180-de76-01c177ae6224"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[0])['text'])\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'this', 'is', 'only', 'somewhat', 'attractive', 'for', 'fans', 'of', '\"', 'bad', 'movie', '\"', 'entertainment', '.', 'it', 'is', 'more', 'worth', '##while', 'for', 'students', 'of', '1970', \"'\", 's', 'pop', 'culture', ':', 'the', 'fashion', '##s', ',', 'the', 'furniture', ',', 'the', 'attitudes', ',', 'and', 'that', 'great', '\"', 'women', \"'\", 's', 'li', '##b', '\"', 'moment', 'of', 'the', 'early', '1970', \"'\", 's', ',', 'when', 'it', 'was', 'still', 'fresh', 'and', 'novel', 'for', 'a', 'self', '-', 'employed', ',', 'independent', 'woman', 'to', 'exist', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', '\"', 'super', '##chi', '##ck', '\"', '(', 'joyce', 'jill', '##son', ')', 'had', 'a', 'mon', '##eta', '##rily', 'reward', '##ing', 'if', 'stu', '##lt', '##ifying', 'career', '(', 'after', 'all', ',', 'what', 'is', 'a', 'flight', 'attendant', 'but', 'a', 'waitress', 'at', '30', ',', '000', 'feet', '-', '-', 'that', 'goes', 'for', 'the', 'male', 'ones', 'too', ')', ',', 'she', 'slept', 'around', 'with', 'multiple', 'men', ',', 'could', 'protect', 'herself', 'and', 'others', '(', 'with', 'karate', ')', 'and', 'wasn', \"'\", 't', 'tied', 'down', 'to', 'anything', '.', 'this', 'is', 'the', 'kind', 'of', 'em', '##an', '##ci', '##pate', '##d', 'woman', 'that', 'scared', 'the', 'juice', '##s', 'out', 'of', 'anti', '-', 'feminist', '##s', ',', 'those', 'retro', '##grade', 'idiots', 'who', 'believe', 'that', 'no', 'woman', 'is', 'complete', 'without', 'a', 'husband', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', '\"', 'sexy', 'steward', '##ess', '\"', 'was', 'a', 'potent', 'arch', '##ety', '##pe', 'of', 'the', 'late', '1960', \"'\", 's', 'to', '1970', \"'\", 's', ',', '(', 'gee', '##z', ',', 'even', 'on', '\"', 'the', 'partridge', 'family', ',', '\"', 'i', 'remember', 'swinging', 'bachelor', 'ruben', 'kincaid', 'constantly', 'hook', '##ing', 'up', 'with', 'steward', '##esses', ')', 'and', 'from', 'that', 'point', 'of', 'view', ',', 'this', 'silly', 'film', 'is', 'an', 'important', 'pop', 'culture', 'time', 'capsule', 'of', 'the', 'pre', '-', 'aids', ',', 'free', '-', 'love', ',', 'women', \"'\", 's', 'li', '##b', ',', 'swinging', 'seventies', '.', 'the', 'plot', 'is', 'quite', 'awful', 'though', '.', 'and', 'for', 'those', 'cave', '##men', 'in', 'the', 'audience', ',', 'there', 'are', 'few', 'bare', 'breasts', 'to', 'look', 'at', '.', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqdJAvo5rxfh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "351dc6ad-94cc-4f9f-eabd-030ada204f2a"
      },
      "source": [
        "LABEL.build_vocab(train_data)\n",
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fcfff64c488>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lzS-oDr2bQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koDa5jv4sGKt",
        "colab_type": "text"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6B4ckJ4sC09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "d525ad82599d456b8193d3497817a23b",
            "18b41f35960c4899b38e68091593851d",
            "08333ecd9456425181194d51964b6c3e",
            "7f0d8a977a85466bb806bf5828e8544e",
            "b0399974672f4feebfebd54d667a5cda",
            "ede328f416fa41d0b24f4899ea118bbf",
            "61dc91d67888411188ef1a22171b4fe9",
            "5aaf5a479f7942fa9c3f680fb85f4a95",
            "089bd16c0b7448e88bed586a8cf57b92",
            "5e693ab34aea4bf399b76028d4bdaa5c",
            "2e1226f82f884885a2ebf7af517629b4",
            "6b05b76174ac4a5c81e521ff089f4bfd",
            "304a6132eb014c0eae72aaddabad4bf1",
            "d1f02a369bf84c74b1d97bab108663f0",
            "ca3b1935f5bd45aaaef0856303eb1188",
            "1b0e6ff11a48482f908104c586aee337"
          ]
        },
        "outputId": "db826846-f394-4d2d-bd17-c27984ba4625"
      },
      "source": [
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d525ad82599d456b8193d3497817a23b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "089bd16c0b7448e88bed586a8cf57b92",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0KNl1Nysnwa",
        "colab_type": "text"
      },
      "source": [
        "Next, build the real model above the base Bert model. Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. These embeddings will then be fed into a GRU to produce a prediction for the sentiment of the input sentence. We get the embedding dimension size (called the `hidden_size`) from the transformer via its config attribute. The rest of the initialization is standard.\n",
        "\n",
        "Within the forward pass, we wrap the transformer in a `no_grad` to ensure no gradients are calculated over this part of the model. The transformer actually returns the embeddings for the whole sequence as well as a *pooled* output. The [documentation](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel) states that the pooled output is \"usually not a good summary of the semantic content of the input, you’re often better with averaging or pooling the sequence of hidden-states for the whole input sequence\", hence we will not be using it. The rest of the forward pass is the standard implementation of a **Bi-GRU** model, where we take the hidden state over the final time-step, and pass it through a linear layer to get our predictions.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpTxSa5SsbhU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BertGRUSentiment(nn.Module):\n",
        "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        self.bert = bert \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size'] ## i.e. 756\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, \n",
        "                          num_layers=n_layers, bidirectional=bidirectional, \n",
        "                          batch_first=True, ### required by the output of bert\n",
        "                          dropout=0 if n_layers < 2 else dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text = [batch_size, sent_len]\n",
        "        with torch.no_grad(): ### turn off grad\n",
        "            embedded = self.bert(text)[0] ### get the output of Bert top layer\n",
        "        # embedded = [batch_size, sent_len, emb_dim]\n",
        "\n",
        "        _, hidden = self.rnn(embedded)\n",
        "        # hidden = [n_layers*n_directions, batch_size, hidden_dim]\n",
        "\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "        # hidden = [batch_size, hidden_dim]\n",
        "\n",
        "        output = self.out(hidden)\n",
        "        # output = [batch_size, output_dim]\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pSqFbcZzja-",
        "colab_type": "text"
      },
      "source": [
        "Next, we create an instance of our model using standard hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcqbiKTTzUNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1 \n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BertGRUSentiment(bert, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1RknYEj0gEV",
        "colab_type": "text"
      },
      "source": [
        "In order to freeze paramers (not train them) we need to set their `requires_grad` attribute to `False`. To do this, we simply loop through all of the `named_parameters` in our model and if they're a part of the `bert` transformer model, we set `requires_grad = False`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si4xStUkz6WP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndjusC3F1AN7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d51fc19-d9ee-4e92-c122-3d5746334769"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,759,169 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbe0AhB91Jns",
        "colab_type": "text"
      },
      "source": [
        "Comparing with fine-tuning the whole Bert model, the # of parameters has reduced from *100M+* to less than *3M*!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6dnW-Uh1tI9",
        "colab_type": "text"
      },
      "source": [
        "We can double check the names of the trainable parameters, ensuring they make sense. As we can see, they are all the parameters of the GRU (rnn) and the linear layer (out)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTe8xe-E1G6k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "1b589ea7-0ab6-40b2-bc30-c02ad826dc07"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRATcn4W13-a",
        "colab_type": "text"
      },
      "source": [
        "## Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QM_QU041wmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaPfCf4X2AeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQJ4JssJ2KPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uf4TwIhB2SEg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vmW05XP2tM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-Nig_Nc3t-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utkZmKUE3wT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7rsggcN3zD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9214ef4c-55cd-44a9-ea95-ee0d0a0b9677"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float(\"inf\")\n",
        "best_model = \"bert_frozen.pt\"\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), best_model)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.505 | Train Acc: 74.03%\n",
            "\t Val. Loss: 0.395 |  Val. Acc: 83.69%\n",
            "Epoch: 2 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.275 | Train Acc: 88.85%\n",
            "\t Val. Loss: 0.258 |  Val. Acc: 89.70%\n",
            "Epoch: 3 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.233 | Train Acc: 90.97%\n",
            "\t Val. Loss: 0.227 |  Val. Acc: 91.00%\n",
            "Epoch: 4 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.207 | Train Acc: 92.04%\n",
            "\t Val. Loss: 0.232 |  Val. Acc: 90.90%\n",
            "Epoch: 5 | Epoch Time: 7m 14s\n",
            "\tTrain Loss: 0.181 | Train Acc: 93.02%\n",
            "\t Val. Loss: 0.228 |  Val. Acc: 91.64%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPo66ByY43qR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3af31501-ffdc-4e3b-a21f-3ef7dbbb21e5"
      },
      "source": [
        "model.load_state_dict(torch.load(best_model))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.202 | Test Acc: 91.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiJrFrcTGQgV",
        "colab_type": "text"
      },
      "source": [
        "The performance is close to, or even slightly better than the fine-tuning results of the whole Bert."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYtP0tRsFB2f",
        "colab_type": "text"
      },
      "source": [
        "## Inference on New Sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VrjHqpiDu5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    #tokens = tokenizer.tokenize(sentence)\n",
        "    #tokens = tokens[:max_input_length-2]\n",
        "    #indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    indexed = tokenizer.encode(sentence)\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTSbBK-JFQRH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8675937-bb54-4c22-fc0c-3bd36e92d48b"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is terrible\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.01239826250821352"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnW7ftHFSeu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57031191-7a37-4a87-e6a8-d6d98f2a7341"
      },
      "source": [
        "predict_sentiment(model, tokenizer, \"This film is great\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9740698933601379"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NGdrZhuHJBz",
        "colab_type": "text"
      },
      "source": [
        "## References:\n",
        "\n",
        "https://colab.research.google.com/github/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb#scrollTo=hSIop_NnLdCx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJHVTS5YFUr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}